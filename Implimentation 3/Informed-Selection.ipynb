{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b56bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This cell sets up the environment, imports necessary libraries, and defines hyperparameters and seeds for reproducibility.\n",
    "'''\n",
    "import os, time, json\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 5e-4\n",
    "EPOCHS = 100\n",
    "K_PERCENTAGE = 0.5\n",
    "K_SAMPLES = int(BATCH_SIZE * K_PERCENTAGE)\n",
    "\n",
    "EPSILON, ALPHA = 8/255, 2/255\n",
    "PGD_STEPS_TRAIN, PGD_STEPS_EVAL = 10, 20\n",
    "\n",
    "SEEDS = [42, 43]\n",
    "\n",
    "NUM_CLASSES = 100\n",
    "METHOD_NAME_TOPK = f\"TopK_CIFAR100_k{K_SAMPLES}_bs{BATCH_SIZE}\"\n",
    "OUT_DIR = \"results_topk_runs\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Method: {METHOD_NAME_TOPK}, K={K_SAMPLES}, BATCH_SIZE={BATCH_SIZE}, seeds={SEEDS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d46fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CIFAR-100 dataset and data loaders\n",
    "'''\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "transform_test = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset  = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(\"Loaded CIFAR-100:\", len(train_dataset), \"train,\", len(test_dataset), \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5076c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PGD attack, utilities, per-class evaluation\n",
    "'''\n",
    "def pgd_attack(model, images, labels, epsilon, alpha, iters):\n",
    "    images = images.clone().detach().to(device)\n",
    "    labels = labels.to(device)\n",
    "    orig = images.clone().detach()\n",
    "    for _ in range(iters):\n",
    "        images.requires_grad = True\n",
    "        outputs = model(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        images = images + alpha * images.grad.sign()\n",
    "        eta = torch.clamp(images - orig, -epsilon, epsilon)\n",
    "        images = torch.clamp(orig + eta, 0.0, 1.0).detach()\n",
    "    return images\n",
    "\n",
    "def compute_overlap_indices(losses, indices_a, indices_b):\n",
    "    sa = set(indices_a.cpu().numpy().tolist())\n",
    "    sb = set(indices_b.cpu().numpy().tolist())\n",
    "    if len(sa) == 0:\n",
    "        return 0.0\n",
    "    return len(sa & sb) / float(len(sa))\n",
    "\n",
    "def compute_selection_stability(list_of_selected_indices, k):\n",
    "    \"\"\"\n",
    "    list_of_selected_indices: list of 1D tensors (selected indices per batch)\n",
    "    stability: average intersection/k between consecutive batches\n",
    "    \"\"\"\n",
    "    if len(list_of_selected_indices) < 2:\n",
    "        return 1.0\n",
    "    scores = []\n",
    "    prev = None\n",
    "    for sel in list_of_selected_indices:\n",
    "        s = set(sel.cpu().numpy().tolist())\n",
    "        if prev is not None:\n",
    "            scores.append(len(prev & s) / float(k))\n",
    "        prev = s\n",
    "    return float(np.mean(scores)) if len(scores)>0 else 0.0\n",
    "\n",
    "def evaluate_per_class(model, data_loader, attack_fn=None, num_classes=NUM_CLASSES):\n",
    "    \"\"\"\n",
    "    Returns overall_acc (float) and per_class_acc (list length=num_classes)\n",
    "    attack_fn: function(model, images, labels, epsilon, alpha, iters) or None\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct_per_class = np.zeros(num_classes, dtype=np.int64)\n",
    "    total_per_class = np.zeros(num_classes, dtype=np.int64)\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for images, labels in data_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        if attack_fn is not None:\n",
    "            images = attack_fn(model, images, labels, EPSILON, ALPHA, PGD_STEPS_EVAL)\n",
    "        with torch.no_grad():\n",
    "            outs = model(images)\n",
    "            _, preds = torch.max(outs, 1)\n",
    "            preds_cpu = preds.cpu().numpy()\n",
    "            labels_cpu = labels.cpu().numpy()\n",
    "            total_correct += int((preds_cpu == labels_cpu).sum())\n",
    "            total_samples += labels_cpu.shape[0]\n",
    "            for c in range(num_classes):\n",
    "                mask = (labels_cpu == c)\n",
    "                if mask.sum() > 0:\n",
    "                    correct_per_class[c] += int((preds_cpu[mask] == c).sum())\n",
    "                    total_per_class[c] += int(mask.sum())\n",
    "    overall_acc = 100.0 * total_correct / total_samples if total_samples>0 else 0.0\n",
    "    per_class_acc = []\n",
    "    for c in range(num_classes):\n",
    "        if total_per_class[c] > 0:\n",
    "            per_class_acc.append(100.0 * correct_per_class[c] / total_per_class[c])\n",
    "        else:\n",
    "            per_class_acc.append(None)\n",
    "    return overall_acc, per_class_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4732976",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This cell defines the training function for one epoch, collects selected indices, computes overlaps, and evaluates the model.\n",
    "'''\n",
    "def train_epoch_topk_collect(model, optimizer, data_loader, k):\n",
    "    '''\n",
    "    Train the model for one epoch, collecting selected indices and computing overlaps.\n",
    "    '''\n",
    "    model.train()\n",
    "    overlaps = []\n",
    "    selected_history = []\n",
    "    for clean_images, labels in data_loader:\n",
    "        clean_images, labels = clean_images.to(device), labels.to(device)\n",
    "        adv_images = pgd_attack(model, clean_images, labels, EPSILON, ALPHA, PGD_STEPS_TRAIN)\n",
    "        combined_images = torch.cat([clean_images, adv_images], dim=0)\n",
    "        combined_labels = torch.cat([labels, labels], dim=0)\n",
    "        with torch.no_grad():\n",
    "            outs = model(combined_images)\n",
    "            losses = F.cross_entropy(outs, combined_labels, reduction='none')\n",
    "\n",
    "        sel_idx = torch.topk(losses, k).indices.to(device)\n",
    "        selected_history.append(sel_idx.clone())\n",
    "\n",
    "        topk_idx = sel_idx\n",
    "        overlap = compute_overlap_indices(losses, topk_idx, sel_idx)\n",
    "        overlaps.append(overlap)\n",
    "\n",
    "        final_images = combined_images[sel_idx]\n",
    "        final_labels = combined_labels[sel_idx]\n",
    "        if final_images.size(0) > 0:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(final_images)\n",
    "            loss = F.cross_entropy(preds, final_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    mean_overlap = float(np.mean(overlaps)) if len(overlaps)>0 else 0.0\n",
    "    stability = compute_selection_stability(selected_history, k)\n",
    "    return mean_overlap, stability\n",
    "\n",
    "def run_experiment_seed_topk(seed, method_name=METHOD_NAME_TOPK):\n",
    "    '''\n",
    "    Run the Top-K experiment with a specific random seed.\n",
    "    '''\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    print(f\"\\n=== TOPK RUN seed {seed} ===\")\n",
    "    model = models.resnet18(weights=None, num_classes=NUM_CLASSES).to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[int(0.75*EPOCHS), int(0.9*EPOCHS)], gamma=0.1)\n",
    "\n",
    "    history = {\n",
    "        'epoch': [],\n",
    "        'std_acc': [],\n",
    "        'robust_acc': [],\n",
    "        'epoch_time': [],\n",
    "        'cumulative_time': [],\n",
    "        'overlap': [],\n",
    "        'selection_stability': [],\n",
    "        'per_class_std_acc': [],\n",
    "        'per_class_robust_acc': []\n",
    "    }\n",
    "\n",
    "    start_time = time.time()\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        t0 = time.time()\n",
    "        mean_overlap, stability = train_epoch_topk_collect(model, optimizer, train_loader, K_SAMPLES)\n",
    "\n",
    "        std_acc, per_class_std = evaluate_per_class(model, test_loader, attack_fn=None, num_classes=NUM_CLASSES)\n",
    "        robust_acc, per_class_rob = evaluate_per_class(model, test_loader, attack_fn=pgd_attack, num_classes=NUM_CLASSES)\n",
    "\n",
    "        scheduler.step()\n",
    "        epoch_time = time.time() - t0\n",
    "        cumulative_time = time.time() - start_time\n",
    "\n",
    "        history['epoch'].append(epoch)\n",
    "        history['std_acc'].append(std_acc)\n",
    "        history['robust_acc'].append(robust_acc)\n",
    "        history['epoch_time'].append(epoch_time)\n",
    "        history['cumulative_time'].append(cumulative_time)\n",
    "        history['overlap'].append(mean_overlap)\n",
    "        history['selection_stability'].append(stability)\n",
    "        history['per_class_std_acc'].append(per_class_std)\n",
    "        history['per_class_robust_acc'].append(per_class_rob)\n",
    "\n",
    "        print(f\"Seed {seed} Epoch {epoch}/{EPOCHS} | Std: {std_acc:.2f}% | Robust: {robust_acc:.2f}% | Overlap: {mean_overlap:.3f} | Stability: {stability:.3f} | EpochTime: {epoch_time:.1f}s\")\n",
    "\n",
    "    out = {\n",
    "        'experiment_name': f\"{method_name}_seed{seed}\",\n",
    "        'hyperparameters': {\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'learning_rate': LEARNING_RATE,\n",
    "            'epochs': EPOCHS,\n",
    "            'k_percentage': K_PERCENTAGE,\n",
    "            'k_samples': K_SAMPLES,\n",
    "            'epsilon': EPSILON\n",
    "        },\n",
    "        'training_history': history,\n",
    "        'final_summary': {\n",
    "            'final_std_acc': history['std_acc'][-1],\n",
    "            'final_robust_acc': history['robust_acc'][-1],\n",
    "            'total_training_time': history['cumulative_time'][-1]\n",
    "        }\n",
    "    }\n",
    "    seed_fname = os.path.join(OUT_DIR, f\"{method_name}_seed{seed}.json\")\n",
    "    with open(seed_fname, 'w') as f:\n",
    "        json.dump(out, f, indent=4)\n",
    "    print(\"Saved TopK seed results to\", seed_fname)\n",
    "    return seed_fname, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1dc5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Run the Top-K experiment with a specific random seed.\n",
    "'''\n",
    "seed_files_topk = []\n",
    "seed_outputs_topk = []\n",
    "\n",
    "for s in SEEDS:\n",
    "    fname, out = run_experiment_seed_topk(s, method_name=METHOD_NAME_TOPK)\n",
    "    seed_files_topk.append(fname)\n",
    "    seed_outputs_topk.append(out)\n",
    "\n",
    "min_epochs = min(len(o['training_history']['epoch']) for o in seed_outputs_topk)\n",
    "metrics = ['std_acc','robust_acc','epoch_time','cumulative_time','overlap','selection_stability']\n",
    "\n",
    "agg_history = {'epoch': list(range(1, min_epochs+1))}\n",
    "for m in metrics:\n",
    "    arr = np.array([o['training_history'][m][:min_epochs] for o in seed_outputs_topk], dtype=float)\n",
    "    agg_history[m + '_mean'] = list(np.nanmean(arr, axis=0))\n",
    "    agg_history[m + '_std']  = list(np.nanstd(arr, axis=0, ddof=1))\n",
    "\n",
    "per_class_std = np.array([o['training_history']['per_class_std_acc'][:min_epochs] for o in seed_outputs_topk], dtype=float)\n",
    "per_class_rob = np.array([o['training_history']['per_class_robust_acc'][:min_epochs] for o in seed_outputs_topk], dtype=float)\n",
    "per_class_std_mean = np.nanmean(per_class_std, axis=0).tolist()\n",
    "per_class_std_std  = np.nanstd(per_class_std, axis=0, ddof=1).tolist()\n",
    "per_class_rob_mean = np.nanmean(per_class_rob, axis=0).tolist()\n",
    "per_class_rob_std  = np.nanstd(per_class_rob, axis=0, ddof=1).tolist()\n",
    "\n",
    "aggregate_output_topk = {\n",
    "    'experiment_name': METHOD_NAME_TOPK + \"_aggregate\",\n",
    "    'seed_files': seed_files_topk,\n",
    "    'hyperparameters': {\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'epochs': EPOCHS,\n",
    "        'k_percentage': K_PERCENTAGE,\n",
    "        'k_samples': K_SAMPLES,\n",
    "        'epsilon': EPSILON\n",
    "    },\n",
    "    'training_history_aggregate': agg_history,\n",
    "    'per_class_std_mean_per_epoch': per_class_std_mean,\n",
    "    'per_class_std_std_per_epoch': per_class_std_std,\n",
    "    'per_class_robust_mean_per_epoch': per_class_rob_mean,\n",
    "    'per_class_robust_std_per_epoch': per_class_rob_std,\n",
    "    'final_summary_aggregate': {\n",
    "        'final_std_acc_mean': float(np.nanmean([o['final_summary']['final_std_acc'] for o in seed_outputs_topk])),\n",
    "        'final_std_acc_std' : float(np.nanstd([o['final_summary']['final_std_acc'] for o in seed_outputs_topk], ddof=1)),\n",
    "        'final_robust_acc_mean': float(np.nanmean([o['final_summary']['final_robust_acc'] for o in seed_outputs_topk])),\n",
    "        'final_robust_acc_std' : float(np.nanstd([o['final_summary']['final_robust_acc'] for o in seed_outputs_topk], ddof=1)),\n",
    "        'total_training_time_mean': float(np.nanmean([o['final_summary']['total_training_time'] for o in seed_outputs_topk])),\n",
    "        'total_training_time_std' : float(np.nanstd([o['final_summary']['total_training_time'] for o in seed_outputs_topk], ddof=1))\n",
    "    }\n",
    "}\n",
    "\n",
    "agg_fname_topk = os.path.join(OUT_DIR, f\"{METHOD_NAME_TOPK}_aggregate.json\")\n",
    "with open(agg_fname_topk, 'w') as f:\n",
    "    json.dump(aggregate_output_topk, f, indent=4)\n",
    "\n",
    "print(\"Saved TopK aggregate results to\", agg_fname_topk)\n",
    "print(\"TopK seed files:\", seed_files_topk)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
